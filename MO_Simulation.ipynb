{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "10cc612b-edc8-4878-a3d0-249ca7319667",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import os\n",
    "import itertools as it\n",
    "from env import *\n",
    "import pandas as pd\n",
    "from MO_agent import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9b01a02-0e93-4b23-8ce2-f911a45e4b34",
   "metadata": {},
   "source": [
    "#### making the environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4af88826-8c33-4c6c-b0e3-27041d6ff911",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'state_change_r2l': 0.1, 'state_change_l2r': 0.1, 'false_observation_get_l_while_r': 0.3, 'false_observation_get_r_while_l': 0.3, 'reward_listen': -0.5, 'reward_low_incorrect': -1, 'reward_high_incorrect': -2, 'reward_low_correct': 1, 'reward_high_correct': 2, 'discount_factor': 0.9, 'initial_wealth': 0}\n"
     ]
    }
   ],
   "source": [
    "e=tiger_POMDP_env(read_config=True,config_address='./tiger.json',parameters=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "871ad54b-1006-4c95-880e-08bb6fe2130d",
   "metadata": {},
   "source": [
    "#### Setting simulation parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "771833b3-5ae0-44e1-8c99-17f03a0345ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "e.reset()\n",
    "initial_observation=[e.current_state]\n",
    "observation=initial_observation\n",
    "state=e.current_state\n",
    "num_to_act=dict(zip(list(e.actions.values()),list(e.actions.keys())))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7102f55c-9d38-423a-900e-6ae67270f30e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters\n",
    "exp_vorfaktoren=[-0.5,0.1]\n",
    "partitioning_chunk_number=100\n",
    "initial_theta=[0.5,0.5]\n",
    "initial_observation=0\n",
    "planning_depth=3\n",
    "maximum_depth=planning_depth\n",
    "\n",
    "internal_state=initial_theta*len(exp_vorfaktoren)\n",
    "internal_state.extend([initial_observation])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c7c0ea1-9dce-4786-8394-237b65d3a9e6",
   "metadata": {},
   "source": [
    "#### Simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6ff03b01-4e45-45ee-96d1-17f0370e2e5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t= 0\n",
      "------\n",
      "state: 1 tiger_left\n",
      "last_observation: 0\n",
      "-------------------------------\n",
      "\n",
      "current internal state: [0.5, 0.5, 0.5, 0.5, 0]\n",
      "\n",
      "             action: listen\n",
      "             **\n",
      "reward: -0.5 new observation: 0\n",
      "\n",
      "new internal state: [0.7, 0.3, 0.7, 0.3, 0]\n",
      "\n",
      "============================\n",
      "t= 1\n",
      "------\n",
      "state: 1 tiger_left\n",
      "last_observation: 0\n",
      "-------------------------------\n",
      "\n",
      "current internal state: [0.7, 0.3, 0.7, 0.3, 0]\n",
      "\n",
      "             action: open_left_low\n",
      "             **\n",
      "reward: -1.0 new observation: 1\n",
      "\n",
      "new internal state: [0.5, 0.5, 0.5, 0.5, 1]\n",
      "\n",
      "============================\n",
      "t= 2\n",
      "------\n",
      "state: 0 tiger_right\n",
      "last_observation: 1\n",
      "-------------------------------\n",
      "\n",
      "current internal state: [0.5, 0.5, 0.5, 0.5, 1]\n",
      "\n",
      "             action: open_right_low\n",
      "             **\n",
      "reward: -1.0 new observation: 0\n",
      "\n",
      "new internal state: [0.5, 0.5, 0.5, 0.5, 0]\n",
      "\n",
      "============================\n"
     ]
    }
   ],
   "source": [
    "ag=Multi_Variate_agent(environment=e, planning_depth=planning_depth, partitioning_chunk_number=partitioning_chunk_number,agent_mode='naive')\n",
    "ag.reset()\n",
    "x_map,M,F,G,X,value_function,all_theta=ag.pre_planning(exp_vorfaktoren, initial_theta=initial_theta,initial_observation=initial_observation)\n",
    "ag.value_iteration()\n",
    "for t in range(maximum_depth):\n",
    "    \n",
    "    print('t=',t)\n",
    "    print('------')\n",
    "    print('state:',state,e.states[state])\n",
    "    print('last_observation:',observation)\n",
    "    print('-------------------------------')\n",
    "    print('')\n",
    "    print('current internal state:',ag.current_internal_state)\n",
    "    print('')\n",
    "    \n",
    "    # agent select the action\n",
    "    action,value_of_action=ag.do_action()\n",
    "    \n",
    "    #environment feedback\n",
    "    t1,t2,state,reward,observation=e.step(num_to_act[action])\n",
    "    \n",
    "    # agent update\n",
    "    new_x=ag.update_agent(new_observation=observation) \n",
    "    \n",
    "    print('             action:',num_to_act[action])  \n",
    "    print ('             **' )\n",
    "    print('reward:',reward,'new observation:',observation)\n",
    "    print('')\n",
    "    print('new internal state:', ag.current_internal_state)\n",
    "    print('')\n",
    "    print('============================')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ed0e91f9-16a0-4964-aefd-524fbf4a6e52",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[-11,  -4],\n",
       "        [ -5,  -5],\n",
       "        [ -7,  -7],\n",
       "        [ -4,  -4],\n",
       "        [ -8,  -8]],\n",
       "\n",
       "       [[-11,  -4],\n",
       "        [ -5,  -5],\n",
       "        [ -7,  -7],\n",
       "        [ -4,  -4],\n",
       "        [ -8,  -8]],\n",
       "\n",
       "       [[-11,  -4],\n",
       "        [ -5,  -5],\n",
       "        [ -7,  -7],\n",
       "        [ -4,  -4],\n",
       "        [ -8,  -8]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[ -4, -11],\n",
       "        [ -7,  -7],\n",
       "        [ -5,  -5],\n",
       "        [ -8,  -8],\n",
       "        [ -4,  -4]],\n",
       "\n",
       "       [[ -4, -11],\n",
       "        [ -7,  -7],\n",
       "        [ -5,  -5],\n",
       "        [ -8,  -8],\n",
       "        [ -4,  -4]],\n",
       "\n",
       "       [[ -4, -11],\n",
       "        [ -7,  -7],\n",
       "        [ -5,  -5],\n",
       "        [ -8,  -8],\n",
       "        [ -4,  -4]]])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "75e1bc36-a6c2-4303-ae80-9590c882e5a6",
   "metadata": {},
   "source": [
    "## Cheating mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "26ee15b0-1afe-43af-9a01-fdd4759c40a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'state_change_r2l': 0.1, 'state_change_l2r': 0.1, 'false_observation_get_l_while_r': 0.3, 'false_observation_get_r_while_l': 0.3, 'reward_listen': -0.5, 'reward_low_incorrect': -1, 'reward_high_incorrect': -2, 'reward_low_correct': 1, 'reward_high_correct': 2, 'discount_factor': 0.9, 'initial_wealth': 0}\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import os\n",
    "import itertools as it\n",
    "from env import *\n",
    "import pandas as pd\n",
    "from MO_agent import *\n",
    "\n",
    "e=tiger_POMDP_env(read_config=True,config_address='./tiger.json',parameters=None)\n",
    "e.reset()\n",
    "initial_observation=[e.current_state]\n",
    "observation=initial_observation\n",
    "state=e.current_state\n",
    "num_to_act=dict(zip(list(e.actions.values()),list(e.actions.keys())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "06e6131e-5057-43f1-987e-c307ecba6a5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters\n",
    "exp_vorfaktoren=[-3,3]\n",
    "partitioning_chunk_number=1000\n",
    "initial_theta=[0.5,0.5]\n",
    "initial_observation=0\n",
    "planning_depth=3\n",
    "maximum_depth=planning_depth\n",
    "\n",
    "internal_state=initial_theta*len(exp_vorfaktoren)\n",
    "internal_state.extend([initial_observation])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb69f50b-55ee-480f-8318-fbc92ed45a5b",
   "metadata": {},
   "source": [
    "#### Simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6014f38a-ed6e-464a-929b-0b3cd19067aa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ag=Multi_Variate_agent(environment=e, planning_depth=planning_depth, partitioning_chunk_number=partitioning_chunk_number,agent_mode='optimized')\n",
    "ag.reset()\n",
    "_,M,F,G,X,value_function,all_theta=ag.pre_planning(exp_vorfaktoren, initial_theta=initial_theta,initial_observation=initial_observation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "21a531bf-821e-4659-9062-4d82af15c040",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: [(0.5, 0.5, 0.5, 0.5, 0)],\n",
       " 1: [(0.7, 0.3, 0.7, 0.3, 0),\n",
       "  (0.3, 0.7, 0.3, 0.7, 1),\n",
       "  (0.5, 0.5, 0.5, 0.5, 0),\n",
       "  (0.5, 0.5, 0.5, 0.5, 1)],\n",
       " 2: [(0.819, 0.181, 0.819, 0.181, 0),\n",
       "  (0.454, 0.546, 0.454, 0.546, 1),\n",
       "  (0.5, 0.5, 0.5, 0.5, 0),\n",
       "  (0.5, 0.5, 0.5, 0.5, 1),\n",
       "  (0.546, 0.454, 0.546, 0.454, 0),\n",
       "  (0.181, 0.819, 0.181, 0.819, 1),\n",
       "  (0.7, 0.3, 0.7, 0.3, 0),\n",
       "  (0.3, 0.7, 0.3, 0.7, 1)]}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ag.reachable_states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "516cb5c6-8432-4f89-8a85-54b85a3899a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t= 0\n",
      "------\n",
      "state: 1 tiger_left\n",
      "last_observation: [1]\n",
      "-------------------------------\n",
      "\n",
      "current internal state: [0.5, 0.5, 0.5, 0.5, 0]\n",
      "\n",
      "             action: open_right_high\n",
      "             **\n",
      "reward: 2.0 new observation: 0\n",
      "\n",
      "new internal state: [0.5, 0.5, 0.5, 0.5, 0]\n",
      "\n",
      "============================\n",
      "t= 1\n",
      "------\n",
      "state: 0 tiger_right\n",
      "last_observation: 0\n",
      "-------------------------------\n",
      "\n",
      "current internal state: [0.5, 0.5, 0.5, 0.5, 0]\n",
      "\n",
      "             action: open_right_high\n",
      "             **\n",
      "reward: -2.0 new observation: 0\n",
      "\n",
      "new internal state: [0.5, 0.5, 0.5, 0.5, 0]\n",
      "\n",
      "============================\n",
      "t= 2\n",
      "------\n",
      "state: 1 tiger_left\n",
      "last_observation: 0\n",
      "-------------------------------\n",
      "\n",
      "current internal state: [0.5, 0.5, 0.5, 0.5, 0]\n",
      "\n",
      "             action: open_right_high\n",
      "             **\n",
      "reward: 2.0 new observation: 1\n",
      "\n",
      "new internal state: [0.5, 0.5, 0.5, 0.5, 1]\n",
      "\n",
      "============================\n"
     ]
    }
   ],
   "source": [
    "\n",
    "ag.value_iteration()\n",
    "for t in range(maximum_depth):\n",
    "    \n",
    "    print('t=',t)\n",
    "    print('------')\n",
    "    print('state:',state,e.states[state])\n",
    "    print('last_observation:',observation)\n",
    "    print('-------------------------------')\n",
    "    print('')\n",
    "    print('current internal state:',ag.current_internal_state)\n",
    "    print('')\n",
    "    \n",
    "    # agent select the action\n",
    "    action,value_of_action=ag.do_action()\n",
    "    \n",
    "    #environment feedback\n",
    "    t1,t2,state,reward,observation=e.step(num_to_act[action])\n",
    "    \n",
    "    # agent update\n",
    "    new_x=ag.update_agent(new_observation=observation) \n",
    "    \n",
    "    print('             action:',num_to_act[action])  \n",
    "    print ('             **' )\n",
    "    print('reward:',reward,'new observation:',observation)\n",
    "    print('')\n",
    "    print('new internal state:', ag.current_internal_state)\n",
    "    print('')\n",
    "    print('============================')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3718417a-7221-42e1-9df3-7327aa1c6f96",
   "metadata": {},
   "outputs": [],
   "source": [
    "ag=Multi_Variate_agent(environment=e, planning_depth=planning_depth, partitioning_chunk_number=partitioning_chunk_number,agent_mode='naive')\n",
    "ag.reset()\n",
    "ag.pre_planning(exp_vorfaktoren, initial_theta=initial_theta,initial_observation=initial_observation)\n",
    "a=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c9095f6-3196-47dc-8803-3f341c6e8078",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
